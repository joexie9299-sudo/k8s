apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-qwen3-0p6b
  namespace: default
  labels:
    app: vllm-qwen3-0p6b
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-qwen3-0p6b
  template:
    metadata:
      labels:
        app: vllm-qwen3-0p6b
    spec:
      nodeSelector:
        gpu: "true"
      runtimeClassName: nvidia

      volumes:
        - name: models-vol
          hostPath:
            path: /root/models
            type: ""
        - name: shm-vol
          emptyDir:
            medium: Memory
            sizeLimit: "2Gi"

      containers:
        - name: vllm
          image: docker.io/vllm/vllm-openai:latest
          imagePullPolicy: IfNotPresent

          command: ["/bin/bash", "-lc"]
          args:
            - |
              set -e
              echo "=== sanity ==="
              which vllm || true
              /usr/local/bin/vllm -v || true
              echo "=== start ==="
              exec /usr/local/bin/vllm serve /root/models/ \
                --host 0.0.0.0 --port 8000 \
                --dtype float16 \
                --max-model-len 4096 \
                --tensor-parallel-size 1 \
                --gpu-memory-utilization 0.80 \
                --max-num-seqs 4 \
                --max-num-batched-tokens 2048 \
                --swap-space 2

          ports:
            - name: http
              containerPort: 8000
              protocol: TCP

          resources:
            requests:
              nvidia.com/gpu: "1"
              cpu: "2"
              memory: "8Gi"
            limits:
              nvidia.com/gpu: "1"
              cpu: "4"
              memory: "16Gi"

          volumeMounts:
            - name: models-vol
              mountPath: /root/models
              readOnly: true
            - name: shm-vol
              mountPath: /dev/shm

          startupProbe:
            tcpSocket:
              port: 8000
            periodSeconds: 5
            failureThreshold: 120
            timeoutSeconds: 2


          livenessProbe:
            tcpSocket:
              port: 8000
            periodSeconds: 20
            timeoutSeconds: 5
            failureThreshold: 6

          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-qwen3-0p6b
  namespace: default
  labels:
    app: vllm-qwen3-0p6b
spec:
  type: NodePort
  selector:
    app: vllm-qwen3-0p6b
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      nodePort: 31800