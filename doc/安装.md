### 安装KUBERNETES工具前，所有机器需要初始化设定
#### HOSTNAME设定
    hostnamectl set-hostname master
    hostnamectl set-hostname node1
    hostnamectl set-hostname node2

#### 统一时区

    sudo timedatectl set-timezone Asia/Shanghai


#### HOSTS设定，集群内所有机器均设定

    vim /etc/hosts
    55.192.0.125 node1
    55.192.0.7 node2
    55.192.0.159 master
    55.192.0.144 node3
    55.192.0.225 gpu1

#### 关闭防火墙

    sudo systemctl stop firewalld
    sudo systemctl disable firewalld
#### 禁用swap

    sudo swapoff -a
    sudo sed -i '/ swap / s/^(.*)$/#1/g' /etc/fstab


#### 修改内核参数

    sudo tee /etc/modules-load.d/containerd.conf <<EOF
    overlay
    br_netfilter
    EOF
    
    sudo modprobe overlay
    sudo modprobe br_netfilter

#### 修改网络参数

    sudo tee /etc/sysctl.d/kubernetes.conf <<EOF
    net.bridge.bridge-nf-call-ip6tables = 1
    net.bridge.bridge-nf-call-iptables = 1
    net.ipv4.ip_forward = 1
    EOF

    ### 使上面配置生效
    sudo sysctl --system


#### 安装containerd

    ## 添加源
    sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

    ## 移除冲突依赖（RHEL默认安装了podman，需要移除）
    sudo dnf remove -y podman buildah cockpit-podman podman-catatonit

    ## 安装containerd
    dnf install containerd.io-1.6.32-3.1.el8

    ## 配置containerd使用systemd作为cgroup
    containerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1
    sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml

    ## 重启并设置开机自启
    sudo systemctl restart containerd
    sudo systemctl enable containerd


#### 安装Kubernetes组件

    # 将 SELinux 设置为 permissive 模式（相当于将其禁用）
    sudo setenforce 0
    sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

    # 添加 Kubernetes 的 yum 仓库
    # 此操作会覆盖 /etc/yum.repos.d/kubernetes.repo 中现存的所有配置
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.34/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.34/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF

    # 安装 kubelet、kubeadm 和 kubectl，并启用 kubelet 以确保它在启动时自动启动:
    sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
    sudo systemctl enable --now kubelet


### Master节点初始化

    # 在主节点执行初始化操作
    sudo kubeadm init --control-plane-endpoint=55.192.0.159


### 添加Node节点

    # 在Master节点执行以下命令，获取到加入集群的指令
    sudo kubeadm token create --print-join-command

    # 将输出的指令，在需要加入集群的Node节点上执行
    kubeadm join 55.192.0.159:6443 --token prsjur.lnaih6vr385ez1of --discovery-token-ca-cert-hash sha256:16a7e60868d8a017de61e32e7aa45adf46343befd14d21fed3fe316999c66b1e 
    
    # 执行完成后，在Master节点查看节点状态
    kubectl get node

### 添加Master节点

    # 在Master节点执行以下命令，
    
    # 
    kubeadm join 55.192.0.159:6443 --token ho8jvb.q5njhyvwfdbkk3f2 --discovery-token-ca-cert-hash sha256:16a7e60868d8a017de61e32e7aa45adf46343befd14d21fed3fe316999c66b1e --certificate-key 42a5938e7308a7cf7cd1fd26b259357b52bbf8fa2ec903701c08d0e47da86d8d --control-plane

### 安装网络插件 calico

    kubectl apply -f crds.yaml
    kubectl apply -f calico.yaml

### 安装kubernetes-dashboard

    # 安装HELM工具
    wget https://get.helm.sh/helm-v3.14.4-linux-amd64.tar.gz
    tar -zxvf helm-v3.14.4-linux-amd64.tar.gz
    sudo mv linux-amd64/helm /usr/local/bin/helm


    # 添加 kubernetes-dashboard 仓库
    helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
    
    # 使用 kubernetes-dashboard Chart 部署名为 `kubernetes-dashboard` 的 Helm Release
    helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard

    # 暴露服务

    # 创建用户
    kubectl apply -f cluster-role-binding.yaml
    kubectl apply -f service-account.yaml

    # 生成token
    kubectl -n kubernetes-dashboard create token admin-user

    # 使用token登录dashboard



### GPU节点调度

前提：按照普通节点的方式Join至集群内

#### 安装GPU驱动

    # 安装编译工具和依赖
    sudo dnf install -y gcc make
    sudo dnf install -y kernel-devel-$(uname -r) kernel-headers-$(uname -r)

    # 下载并安装驱动
    wget https://us.download.nvidia.com/XFree86/Linux-x86_64/550.54.14/NVIDIA-Linux-x86_64-550.54.14.run
    chmod +x NVIDIA-Linux-x86_64-550.54.14.run
    sudo ./NVIDIA-Linux-x86_64-550.54.14.run

    # 验证
    nvidia-smi

#### 安装k8s-device-plugin

##### nvidia-container-runtime 安装并配置（https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html）

    # 配置源
    curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \
    sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo

    # 安装
    export NVIDIA_CONTAINER_TOOLKIT_VERSION=1.18.1-1
    sudo dnf install -y \
    nvidia-container-toolkit-${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
    nvidia-container-toolkit-base-${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
    libnvidia-container-tools-${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
    libnvidia-container1-${NVIDIA_CONTAINER_TOOLKIT_VERSION}

    # 配置
    sudo nvidia-ctk runtime configure --runtime=containerd
    sudo systemctl restart containerd

#### nvidia-device-plugin 安装

    helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
    helm repo update
    helm upgrade -i nvdp nvdp/nvidia-device-plugin \
    --namespace nvidia-device-plugin \
    --create-namespace \
    --version 0.17.1

#### NVIDIA GPU Operator 安装 https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html#operator-install-guide

    kubectl create ns gpu-operator
    
    kubectl label --overwrite ns gpu-operator pod-security.kubernetes.io/enforce=privileged
        
    helm repo add nvidia https://helm.ngc.nvidia.com/nvidia \
        && helm repo update

    helm install --wait --generate-name \
    -n gpu-operator --create-namespace \
    nvidia/gpu-operator \
    --version=v25.10.1