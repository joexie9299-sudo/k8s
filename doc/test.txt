apiVersion: v1
kind: Pod
metadata:
  annotations:
    cni.projectcalico.org/containerID: 795960b6ad5fdfa9bd4051061ac3a2e933b9a1c882fcd0c0ab6c42fb83623e01
    cni.projectcalico.org/podIP: 192.168.5.211/32
    cni.projectcalico.org/podIPs: 192.168.5.211/32
  creationTimestamp: "2026-01-10T04:30:13Z"
  generateName: nvidia-cuda-validator-
  generation: 1
  labels:
    app: nvidia-cuda-validator
  name: nvidia-cuda-validator-bmfrd
  namespace: gpu-operator
  ownerReferences:
  - apiVersion: nvidia.com/v1
    blockOwnerDeletion: true
    controller: true
    kind: ClusterPolicy
    name: cluster-policy
    uid: cb291e37-9477-4558-9433-06fe53c7a6dc
  resourceVersion: "23902"
  uid: 571890fb-7a1b-41e0-8a4e-948d899ec863
spec:
  containers:
  - args:
    - echo cuda workload validation is successful
    command:
    - sh
    - -c
    image: nvcr.io/nvidia/gpu-operator:v25.10.1
    imagePullPolicy: IfNotPresent
    name: nvidia-cuda-validator
    resources: {}
    securityContext:
      privileged: true
      readOnlyRootFilesystem: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-tlfbh
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  initContainers:
  - args:
    - vectorAdd
    command:
    - sh
    - -c
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: all
    image: nvcr.io/nvidia/gpu-operator:v25.10.1
    imagePullPolicy: IfNotPresent
    name: cuda-validation
    resources: {}
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-tlfbh
      readOnly: true
  nodeName: gpu1
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: OnFailure
  runtimeClassName: nvidia
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: nvidia-operator-validator
  serviceAccountName: nvidia-operator-validator
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: kube-api-access-tlfbh
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2026-01-10T04:30:14Z"
    observedGeneration: 1
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2026-01-10T04:30:13Z"
    message: 'containers with incomplete status: [cuda-validation]'
    observedGeneration: 1
    reason: ContainersNotInitialized
    status: "False"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2026-01-10T04:30:13Z"
    message: 'containers with unready status: [nvidia-cuda-validator]'
    observedGeneration: 1
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2026-01-10T04:30:13Z"
    message: 'containers with unready status: [nvidia-cuda-validator]'
    observedGeneration: 1
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2026-01-10T04:30:13Z"
    observedGeneration: 1
    status: "True"
    type: PodScheduled
  containerStatuses:
  - image: nvcr.io/nvidia/gpu-operator:v25.10.1
    imageID: ""
    lastState: {}
    name: nvidia-cuda-validator
    ready: false
    restartCount: 0
    started: false
    state:
      waiting:
        reason: PodInitializing
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-tlfbh
      readOnly: true
      recursiveReadOnly: Disabled
  hostIP: 55.192.0.225
  hostIPs:
  - ip: 55.192.0.225
  initContainerStatuses:
  - containerID: containerd://0b96b413b96e7043729ed63fb822d5084d08f0a1f874de94d9e4d732c3182271
    image: nvcr.io/nvidia/gpu-operator:v25.10.1
    imageID: nvcr.io/nvidia/gpu-operator@sha256:634471cdfedcc3bd6b4412a905a9fbc9a9bf91df7f436aa00454b088d087c60a
    lastState:
      terminated:
        containerID: containerd://0b96b413b96e7043729ed63fb822d5084d08f0a1f874de94d9e4d732c3182271
        exitCode: 1
        finishedAt: "2026-01-10T04:31:45Z"
        reason: Error
        startedAt: "2026-01-10T04:31:45Z"
    name: cuda-validation
    ready: false
    resources: {}
    restartCount: 4
    started: false
    state:
      waiting:
        message: back-off 1m20s restarting failed container=cuda-validation pod=nvidia-cuda-validator-bmfrd_gpu-operator(571890fb-7a1b-41e0-8a4e-948d899ec863)
        reason: CrashLoopBackOff
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-tlfbh
      readOnly: true
      recursiveReadOnly: Disabled
  observedGeneration: 1
  phase: Pending
  podIP: 192.168.5.211
  podIPs:
  - ip: 192.168.5.211
  qosClass: BestEffort
  startTime: "2026-01-10T04:30:13Z"