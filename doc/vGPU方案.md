# GPU 虚拟化方案对比

| 特性             | **MIG (Multi-Instance GPU)**                                 | **vGPU (NVIDIA vGPU)**                                | **Time-slicing**                                    | **HAMi**                                                     |
| ---------------- | ------------------------------------------------------------ | ----------------------------------------------------- | --------------------------------------------------- | ------------------------------------------------------------ |
| **原理**         | 将物理 GPU 硬件级切分为多个独立实例，每个实例有独立的显存和计算核心 | 通过驱动层虚拟化，将 GPU 显存和算力分配给多个 VM/容器 | GPU 按时间片轮流分配给不同任务，类似 CPU 时间片调度 | 结合硬件和软件，动态映射 GPU 内存，支持灵活的 vGPU 切分      |
| **隔离性**       | 高：硬件级隔离，每个实例独立运行                             | 高：虚拟机级隔离，资源分配明确                        | 低：共享 GPU 核心和显存，容易互相影响               | 中等：内存共享但访问隔离，性能和安全性介于 MIG 与 Time-slicing 之间 |
| **性能开销**     | 低：接近原生性能                                             | 低：接近原生性能，但需付费许可                        | 中等：约 5–10% 调度开销                             | 低到中等：依赖实现，通常能保持 90% 以上性能                  |
| **资源分配方式** | 静态分割，固定 profile                                       | 静态/动态分配，需 vGPU license                        | 动态共享，按时间片切换                              | 动态分割，支持显存/算力灵活配置                              |
| **适用场景**     | 高端 GPU（如 A100/H100），需要强隔离和稳定性能的 AI 训练     | 企业虚拟桌面、AI 推理，需官方支持和稳定性             | 测试环境或轻量任务，适合低成本共享                  | 开源环境，适合成本敏感场景，提升 GPU 利用率                  |
| **厂商/来源**    | NVIDIA 官方                                                  | NVIDIA 官方（需商业授权）                             | NVIDIA 驱动内置模式                                 | 开源社区（最初由第四范式开发）                               |

